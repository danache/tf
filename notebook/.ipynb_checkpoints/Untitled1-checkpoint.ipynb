{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bnrc2/mu/tf\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from skimage import transform\n",
    "import scipy.misc as scm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorlayer as tl\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.img_tf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from skimage import transform\n",
    "import scipy.misc as scm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorlayer as tl\n",
    "class DataGenerator():\n",
    "    def __init__(self, imgdir=None, label_dir=None, out_record=None, num_txt=\"\", nstack=4, resize=256, scale=0.25,\n",
    "                 flipping=False,\n",
    "                 color_jitting=30, rotate=30, batch_size=32, name=\"\", is_aug=True, isvalid=False, refine_num=None):\n",
    "        self.nstack = nstack\n",
    "        if is_aug:\n",
    "            self.flipping = flipping\n",
    "            self.color_jitting = color_jitting\n",
    "            self.rotate = rotate\n",
    "        else:\n",
    "\n",
    "            self.flipping = False\n",
    "            self.color_jitting = False\n",
    "            self.rotate = False\n",
    "        self.num_txt = num_txt\n",
    "        self.scale = scale\n",
    "        self.isvalid = isvalid\n",
    "        self.resize = resize\n",
    "        self.batch_size = batch_size\n",
    "        self.name = name\n",
    "        self.refine_num = refine_num\n",
    "        if self.refine_num:\n",
    "            print(\"max num is \" + str(refine_num))\n",
    "        if os.path.exists(out_record):\n",
    "            print(out_record)\n",
    "            print(\"record file exist!!\")\n",
    "            self.record_path = out_record\n",
    "            txt = open(num_txt, \"r\")\n",
    "\n",
    "            for line in txt.readlines():\n",
    "                self.number = int(line.strip())\n",
    "\n",
    "        else:\n",
    "            print(self.name + \"record file not exist!  creating !!!\")\n",
    "            self.generageRecord(imgdir, label_dir, out_record, extension=self.scale, resize=256)\n",
    "            self.record_path = out_record\n",
    "\n",
    "    def getData(self):\n",
    "        return self.read_and_decode(filename=self.record_path, flipping=self.flipping,\n",
    "                                    color_jitting=self.color_jitting, rotate=self.rotate, batch_size=self.batch_size,\n",
    "                                    isvalid=self.isvalid)\n",
    "\n",
    "    def getN(self):\n",
    "        return self.number\n",
    "\n",
    "    def _bytes_feature(self, value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    # def augment(self,):\n",
    "    #     #包括resize to size, scaling ,fliping, color jitting, rotate,\n",
    "\n",
    "    def generageRecord(self, imgdir, label_tmp, out_record, extension=0.3, resize=256):\n",
    "        writer = tf.python_io.TFRecordWriter(out_record)\n",
    "        self.number = 0\n",
    "        label_tmp = pd.read_json(label_tmp)\n",
    "        for index, row in label_tmp.iterrows():\n",
    "            anno = row[\"human_annotations\"]\n",
    "            #         if(len(anno.keys())  == 1):\n",
    "            #             continue\n",
    "            img_path = os.path.join(imgdir, row[\"image_id\"] + \".jpg\")\n",
    "\n",
    "            img = scm.imread(img_path)\n",
    "\n",
    "            w, h = img.shape[1], img.shape[0]\n",
    "            keypoint = row[\"keypoint_annotations\"]\n",
    "            i = 0\n",
    "            for key in anno.keys():\n",
    "                i += 1\n",
    "                if (anno[key][0] >= anno[key][2] or anno[key][1] >= anno[key][3]):\n",
    "                    print(img_path)\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = anno[key][0], anno[key][1], anno[key][2], anno[key][3]\n",
    "\n",
    "                board_w = x2 - x1\n",
    "                board_h = y2 - y1\n",
    "                center = np.array(((x1 + x2) * 0.5, (y1 + y2) * 0.5))\n",
    "                scale = np.array((board_h, board_w))\n",
    "                ankle = keypoint[key].copy()\n",
    "\n",
    "                new_img = img.astype(np.uint8)\n",
    "\n",
    "                feature = {\n",
    "                    'label': self._bytes_feature(tf.compat.as_bytes(np.array(ankle).astype(np.int32).tostring())),\n",
    "                    'img_raw': self._bytes_feature(tf.compat.as_bytes(new_img.tostring())),\n",
    "                    'center': self._bytes_feature(tf.compat.as_bytes(center.astype(np.float32).tostring())),\n",
    "                    'h': tf.train.Feature(int64_list=tf.train.Int64List(value=[h])),\n",
    "                    'w': tf.train.Feature(int64_list=tf.train.Int64List(value=[w])),\n",
    "                    'bh': tf.train.Feature(int64_list=tf.train.Int64List(value=[board_h])),\n",
    "                    'bw': tf.train.Feature(int64_list=tf.train.Int64List(value=[board_w])),\n",
    "                    'img_name': self._bytes_feature(tf.compat.as_bytes(row[\"image_id\"])),\n",
    "                }\n",
    "\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example.SerializeToString())\n",
    "                self.number += 1\n",
    "            if index % 100 == 0:\n",
    "                print(\"creating -- %d\" % (index))\n",
    "            if self.refine_num:\n",
    "                if index > self.refine_num:\n",
    "                    break\n",
    "        writer.close()\n",
    "        txt = open(self.num_txt, \"w\")\n",
    "        txt.write(str(self.number))\n",
    "        txt.close()\n",
    "        return None\n",
    "\n",
    "    def _makeGaussian(self, height, width, sigma=3., center=None, flag=True):\n",
    "        \"\"\" Make a square gaussian kernel.\n",
    "        size is the length of a side of the square\n",
    "        sigma is full-width-half-maximum, which\n",
    "        can be thought of as an effective radius.\n",
    "        \"\"\"\n",
    "        x = tf.range(0., width, 1.)\n",
    "        y = tf.range(0., height, 1.)[:, tf.newaxis]\n",
    "        if center is None:\n",
    "\n",
    "            x0 = width // 2\n",
    "            y0 = height // 2\n",
    "        else:\n",
    "\n",
    "            x0 = center[0]\n",
    "            y0 = center[1]\n",
    "\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        y = tf.cast(y, tf.float32)\n",
    "        x0 = tf.cast(x0, tf.float32)\n",
    "        y0 = tf.cast(y0, tf.float32)\n",
    "\n",
    "        dx = tf.pow(tf.subtract(x, x0), 2)\n",
    "        dy = tf.pow(tf.subtract(y, y0), 2)\n",
    "        fenzi = tf.multiply(tf.multiply(tf.add(dx, dy), tf.log(2.)), -4.0)\n",
    "        fenmu = tf.cast(tf.pow(sigma, 2), tf.float32)\n",
    "        dv = tf.divide(fenzi, fenmu)\n",
    "        return tf.exp(dv)\n",
    "\n",
    "    def planB(self, height, width):\n",
    "        return tf.zeros((height, width))\n",
    "\n",
    "    def generateHeatMap(self, height, width, joints, num_joints, maxlenght):\n",
    "\n",
    "        hm = []\n",
    "        coord = []\n",
    "        for i in range(int(num_joints)):\n",
    "\n",
    "            tmp = (tf.sqrt(maxlenght) * maxlenght * 10 / 4096.) + 2\n",
    "            s = tf.cast(tmp, tf.int32)\n",
    "            x = tf.cast(joints[i * 3], tf.float64)\n",
    "            y = tf.cast(joints[i * 3 + 1], tf.float64)\n",
    "\n",
    "            ht = tf.cond(\n",
    "                (tf.equal(joints[i * 3 + 2], 1.)),\n",
    "                lambda: self._makeGaussian(height, width, s,\n",
    "                                           center=(tf.cast(x , tf.int32), tf.cast(y , tf.int32))),\n",
    "                lambda: self.planB(height, width)\n",
    "            )\n",
    "            ht = tf.expand_dims(ht, -1)\n",
    "            hm.append(ht)\n",
    "\n",
    "        return hm\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def read_and_decode(self, filename, img_size=256,label_size=14, heatmap_size=64,  flipping=False,\n",
    "                        color_jitting=True, rotate=30, batch_size=32, isvalid=False):\n",
    "\n",
    "        feature = {'img_raw': tf.FixedLenFeature([], tf.string),\n",
    "                   'label': tf.FixedLenFeature([], tf.string),\n",
    "                   'center': tf.FixedLenFeature([], tf.string),\n",
    "                   'h': tf.FixedLenFeature([], tf.int64),\n",
    "                   'w': tf.FixedLenFeature([], tf.int64),\n",
    "                   'bh': tf.FixedLenFeature([], tf.int64),\n",
    "                   'bw': tf.FixedLenFeature([], tf.int64),\n",
    "\n",
    "                   'img_name': tf.FixedLenFeature([], tf.string),\n",
    "                   }\n",
    "        # Create a list of filenames and pass it to a queue\n",
    "        filename_queue = tf.train.string_input_producer([filename])\n",
    "        # Define a reader and read the next record\n",
    "\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "        # Decode the record read by the reader\n",
    "        features = tf.parse_single_example(serialized_example, features=feature)\n",
    "        # Convert the image data from string back to the numbers\n",
    "\n",
    "\n",
    "\n",
    "        center = tf.decode_raw(features['center'], tf.float32)\n",
    "        center = tf.reshape(center, [2, ])\n",
    "\n",
    "        label = tf.decode_raw(features['label'], tf.int32)\n",
    "        label = tf.reshape(label, [label_size, 3])\n",
    "        label=tf.cast(label,tf.float32)\n",
    "\n",
    "        height = tf.cast(features['h'], tf.int32)\n",
    "        width = tf.cast(features['w'], tf.int32)\n",
    "\n",
    "        boxh = tf.cast(features['bh'], tf.int32)\n",
    " \n",
    "        boxw = tf.cast(features['bw'], tf.int32)\n",
    "        \n",
    "        \n",
    "        img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "\n",
    "        # Cast label data into int32\n",
    "        # label = tf.cast(features['label'],tf.float32)\n",
    "        # Reshape image data into the original shape\n",
    "\n",
    "        img_name = features['img_name']\n",
    "        res_256 = tf.constant([img_size,img_size],dtype=tf.float32)\n",
    "        res_64 = tf.constant([heatmap_size,heatmap_size],dtype=tf.float32)\n",
    "        \n",
    "        #return center,boxh,boxw\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        scale = tf.stack([boxh,boxw],axis=0)\n",
    "        scale=tf.cast(scale,tf.float32)\n",
    "        img = tf.reshape(img, [height, width, 3])\n",
    "\n",
    "        crop_img = crop(img,height, width,center, scale, res_256,)\n",
    "        crop_img.set_shape([img_size,img_size,3])\n",
    "\n",
    "        coord = transformPreds(coords=label[:, 0:2], center=center,\n",
    "                                    scale=scale, res=res_64)\n",
    "        coord = tf.squeeze(coord)\n",
    "        label_exp =tf.expand_dims( label[:,-1], -1)\n",
    "        coord = tf.squeeze(tf.reshape(tf.concat([coord,label_exp],axis=1),[-1,1]))\n",
    "        heatmap = self.generateHeatMap(heatmap_size, heatmap_size, coord, label_size , heatmap_size * 1.)\n",
    "        repeat = []\n",
    "        for i in range(len(heatmap)):\n",
    "            heatmap[i] = tf.squeeze(heatmap[i])\n",
    "        heatmap = tf.stack(heatmap,axis=-1)\n",
    "        for i in range(self.nstack):\n",
    "            repeat.append(heatmap)\n",
    "        heatmap = tf.stack(repeat, axis=0)\n",
    "        \n",
    "        if batch_size:\n",
    "    \n",
    "                min_after_dequeue = 10\n",
    "                capacity = min_after_dequeue + 4 * batch_size\n",
    "                return tf.train.shuffle_batch([crop_img, heatmap, center,scale, img_name,label,coord],\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               num_threads=4,\n",
    "                                                               capacity=capacity,\n",
    "                                                               min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "        else:\n",
    "            return img, label\n",
    "    \n",
    "\n",
    "    def start(self):\n",
    "        crop_img, heatmap, center,scale, img_name,gt,crd = self.getData()\n",
    "        rever = reverseFromHt(heatmap, nstack=self.nstack, batch_size=self.batch_size, num_joint=14, scale=scale, center=center, res=[64, 64])\n",
    "        \n",
    "        scale = tf.cast(tf.squeeze(tf.transpose(scale)), tf.float32)\n",
    "        center = tf.cast(tf.squeeze(tf.transpose(center)), tf.float32)\n",
    "        label = tf.reshape(crd,[14,3])\n",
    "        ori_rever =  transformPreds(label[:, 0:2], center, scale, tf.constant([64., 64.]), reverse=1)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        init = tf.group(tf.global_variables_initializer(),\n",
    "                        tf.local_variables_initializer())\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=self.sess)\n",
    "\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        for i in range(1):\n",
    "            rev,ori,gts = self.sess.run([rever,ori_rever, gt,]) \n",
    "            cr = self.sess.run(crd)\n",
    "#         print(a1,b1,c1,d1,e1,f1)\n",
    "        print(ori,cr)\n",
    "        coord.request_stop()\n",
    "        #\n",
    "        #     # Wait for threads to finish.\n",
    "        coord.join(threads)\n",
    "        self.sess.close()\n",
    "        return rev,ori,gts\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max num is 10000\n",
      "/media/bnrc2/_backup/dataset/new_tfrecord/test.tfrecords\n",
      "record file exist!!\n"
     ]
    }
   ],
   "source": [
    "test = DataGenerator(imgdir=\"/media/bnrc2/_backup/ai/ai_challenger_keypoint_train_20170902/keypoint_train_images_20170902/\", nstack= 2,label_dir=\"/media/bnrc2/_backup/ai/ai_challenger_keypoint_train_20170902/keypoint_train_annotations_20170909.json\",\n",
    "                               out_record=\"/media/bnrc2/_backup/dataset/new_tfrecord/test.tfrecords\",num_txt=\"/media/bnrc2/_backup/dataset/new_tfrecord/test.txt\",\n",
    "                               batch_size=1, name=\"train_mini\", is_aug=False,isvalid=False, refine_num = 10000)\n",
    "\n",
    "init = tf.group(tf.global_variables_initializer(),\n",
    "                    tf.local_variables_initializer())\n",
    "\n",
    "a ,b,c= test.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.reshape(a,[14,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 602.99993896,  253.99998474],\n",
       "       [ 602.99993896,  253.99998474],\n",
       "       [ 602.99993896,  253.99998474],\n",
       "       [ 708.98431396,  316.21871948],\n",
       "       [ 667.42181396,  367.125     ],\n",
       "       [ 627.93743896,  384.09375   ],\n",
       "       [ 602.99993896,  253.99998474],\n",
       "       [ 602.99993896,  253.99998474],\n",
       "       [ 602.99993896,  253.99998474],\n",
       "       [ 681.96868896,  412.375     ],\n",
       "       [ 696.51556396,  502.875     ],\n",
       "       [ 704.82806396,  582.0625    ],\n",
       "       [ 708.98431396,  259.65621948],\n",
       "       [ 708.98431396,  304.90621948]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 719.          320.        ]\n",
      " [ 666.99993896  365.        ]\n",
      " [ 627.          385.        ]\n",
      " [ 709.          320.        ]\n",
      " [ 669.          369.        ]\n",
      " [ 628.          388.        ]\n",
      " [ 691.          422.        ]\n",
      " [ 699.99993896  508.        ]\n",
      " [ 700.99993896  585.        ]\n",
      " [ 683.99993896  417.00003052]\n",
      " [ 696.99993896  508.        ]\n",
      " [ 706.          587.        ]\n",
      " [ 709.          260.00003052]\n",
      " [ 710.          310.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(b.reshape([14,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 719.  320.    2.]\n",
      "  [ 667.  365.    2.]\n",
      "  [ 627.  385.    2.]\n",
      "  [ 709.  320.    1.]\n",
      "  [ 669.  369.    1.]\n",
      "  [ 628.  388.    1.]\n",
      "  [ 691.  422.    2.]\n",
      "  [ 700.  508.    2.]\n",
      "  [ 701.  585.    2.]\n",
      "  [ 684.  417.    1.]\n",
      "  [ 697.  508.    1.]\n",
      "  [ 706.  587.    1.]\n",
      "  [ 709.  260.    1.]\n",
      "  [ 710.  310.    1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.squeeze(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = a[0,:].astype(np.uint8)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = b[0,0,:]\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = np.zeros([14,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for joint in range(label.shape[-1]):\n",
    "    single_data = label\n",
    "    idx = np.unravel_index(single_data[:, :, joint].argmax(), (64, 64))\n",
    "   \n",
    "\n",
    "    res[joint][0] = idx[1]\n",
    "    res[joint][1] = idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (res * 4).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(14):\n",
    "    cv2.circle(im, (int(res[i][0]) , int(res[i][1])) , 5, (0, 255, 155), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "a1 = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(b.shape[0]):\n",
    "    cv2.circle(a1, (int(b[i][0]) , int(b[i][1])) , 1, (0, 255, 155), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = (422,382.5)\n",
    "scale = (569,179)\n",
    "\n",
    "x1 = center[0] - scale[1] /2\n",
    "x2 = center[0] + scale[1] / 2\n",
    "y1 = center[1] - scale[0] / 2\n",
    "y2 = center[1] + scale[0] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.line(a,(int(x1),int(y1)), (int(x1), int(y2)),(0,255,255),10)\n",
    "cv2.line(a,(int(x1),int(y1)), (int(x2), int(y1)),(0,255,255),10)\n",
    "cv2.line(a,(int(x2),int(y2)), (int(x1), int(y2)),(0,255,255),10)\n",
    "cv2.line(a,(int(x2),int(y2)), (int(x2), int(y1)),(0,255,255),10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(ori.shape[0]):\n",
    "    cv2.circle(im, (int(ori[i][0]), int(ori[i][1])), 10, (0, 255, 155), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg = [65,65]\n",
    "print(gg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.reshape(a,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.cast(tf.argmax(b,0),tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.cast(tf.div(c,tf.constant([64],dtype=tf.int32)),tf.int32)\n",
    "e = tf.subtract(c, tf.multiply(d,tf.constant([64],dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run([d,e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a.reshape([-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf14]",
   "language": "python",
   "name": "conda-env-tf14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
