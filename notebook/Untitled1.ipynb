{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bnrc2/mu/tf\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from skimage import transform\n",
    "import scipy.misc as scm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorlayer as tl\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tools.img_tf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from skimage import transform\n",
    "import scipy.misc as scm\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorlayer as tl\n",
    "class DataGenerator():\n",
    "    def __init__(self, imgdir=None, label_dir=None, out_record=None, num_txt=\"\", nstack=4, resize=256, scale=0.25,\n",
    "                 flipping=False,\n",
    "                 color_jitting=30, rotate=30, batch_size=32, name=\"\", is_aug=True, isvalid=False, refine_num=None):\n",
    "        self.nstack = nstack\n",
    "        if is_aug:\n",
    "            self.flipping = flipping\n",
    "            self.color_jitting = color_jitting\n",
    "            self.rotate = rotate\n",
    "        else:\n",
    "\n",
    "            self.flipping = False\n",
    "            self.color_jitting = False\n",
    "            self.rotate = False\n",
    "        self.num_txt = num_txt\n",
    "        self.scale = scale\n",
    "        self.isvalid = isvalid\n",
    "        self.resize = resize\n",
    "        self.batch_size = batch_size\n",
    "        self.name = name\n",
    "        self.refine_num = refine_num\n",
    "        if self.refine_num:\n",
    "            print(\"max num is \" + str(refine_num))\n",
    "        if os.path.exists(out_record):\n",
    "            print(out_record)\n",
    "            print(\"record file exist!!\")\n",
    "            self.record_path = out_record\n",
    "            txt = open(num_txt, \"r\")\n",
    "\n",
    "            for line in txt.readlines():\n",
    "                self.number = int(line.strip())\n",
    "\n",
    "        else:\n",
    "            print(self.name + \"record file not exist!  creating !!!\")\n",
    "            self.generageRecord(imgdir, label_dir, out_record, extension=self.scale, resize=256)\n",
    "            self.record_path = out_record\n",
    "\n",
    "    def getData(self):\n",
    "        return self.read_and_decode(filename=self.record_path, flipping=self.flipping,\n",
    "                                    color_jitting=self.color_jitting, rotate=self.rotate, batch_size=self.batch_size,\n",
    "                                    isvalid=self.isvalid)\n",
    "\n",
    "    def getN(self):\n",
    "        return self.number\n",
    "\n",
    "    def _bytes_feature(self, value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    # def augment(self,):\n",
    "    #     #包括resize to size, scaling ,fliping, color jitting, rotate,\n",
    "\n",
    "    def generageRecord(self, imgdir, label_tmp, out_record, extension=0.3, resize=256):\n",
    "        writer = tf.python_io.TFRecordWriter(out_record)\n",
    "        self.number = 0\n",
    "        label_tmp = pd.read_json(label_tmp)\n",
    "        for index, row in label_tmp.iterrows():\n",
    "            anno = row[\"human_annotations\"]\n",
    "            #         if(len(anno.keys())  == 1):\n",
    "            #             continue\n",
    "            img_path = os.path.join(imgdir, row[\"image_id\"] + \".jpg\")\n",
    "\n",
    "            img = scm.imread(img_path)\n",
    "\n",
    "            w, h = img.shape[1], img.shape[0]\n",
    "            keypoint = row[\"keypoint_annotations\"]\n",
    "            i = 0\n",
    "            for key in anno.keys():\n",
    "                i += 1\n",
    "                if (anno[key][0] >= anno[key][2] or anno[key][1] >= anno[key][3]):\n",
    "                    print(img_path)\n",
    "                    continue\n",
    "\n",
    "                x1, y1, x2, y2 = anno[key][0], anno[key][1], anno[key][2], anno[key][3]\n",
    "\n",
    "                board_w = x2 - x1\n",
    "                board_h = y2 - y1\n",
    "                center = np.array(((x1 + x2) * 0.5, (y1 + y2) * 0.5))\n",
    "                scale = np.array((board_h, board_w))\n",
    "                ankle = keypoint[key].copy()\n",
    "\n",
    "                new_img = img.astype(np.uint8)\n",
    "\n",
    "                feature = {\n",
    "                    'label': self._bytes_feature(tf.compat.as_bytes(np.array(ankle).astype(np.int32).tostring())),\n",
    "                    'img_raw': self._bytes_feature(tf.compat.as_bytes(new_img.tostring())),\n",
    "                    'center': self._bytes_feature(tf.compat.as_bytes(center.astype(np.float32).tostring())),\n",
    "                    'h': tf.train.Feature(int64_list=tf.train.Int64List(value=[h])),\n",
    "                    'w': tf.train.Feature(int64_list=tf.train.Int64List(value=[w])),\n",
    "                    'bh': tf.train.Feature(int64_list=tf.train.Int64List(value=[board_h])),\n",
    "                    'bw': tf.train.Feature(int64_list=tf.train.Int64List(value=[board_w])),\n",
    "                    'img_name': self._bytes_feature(tf.compat.as_bytes(row[\"image_id\"])),\n",
    "                }\n",
    "\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example.SerializeToString())\n",
    "                self.number += 1\n",
    "            if index % 100 == 0:\n",
    "                print(\"creating -- %d\" % (index))\n",
    "            if self.refine_num:\n",
    "                if index > self.refine_num:\n",
    "                    break\n",
    "        writer.close()\n",
    "        txt = open(self.num_txt, \"w\")\n",
    "        txt.write(str(self.number))\n",
    "        txt.close()\n",
    "        return None\n",
    "\n",
    "    def _makeGaussian(self, height, width, sigma=3., center=None, flag=True):\n",
    "        \"\"\" Make a square gaussian kernel.\n",
    "        size is the length of a side of the square\n",
    "        sigma is full-width-half-maximum, which\n",
    "        can be thought of as an effective radius.\n",
    "        \"\"\"\n",
    "        x = tf.range(0., width, 1.)\n",
    "        y = tf.range(0., height, 1.)[:, tf.newaxis]\n",
    "        if center is None:\n",
    "\n",
    "            x0 = width // 2\n",
    "            y0 = height // 2\n",
    "        else:\n",
    "\n",
    "            x0 = center[0]\n",
    "            y0 = center[1]\n",
    "\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        y = tf.cast(y, tf.float32)\n",
    "        x0 = tf.cast(x0, tf.float32)\n",
    "        y0 = tf.cast(y0, tf.float32)\n",
    "\n",
    "        dx = tf.pow(tf.subtract(x, x0), 2)\n",
    "        dy = tf.pow(tf.subtract(y, y0), 2)\n",
    "        fenzi = tf.multiply(tf.multiply(tf.add(dx, dy), tf.log(2.)), -4.0)\n",
    "        fenmu = tf.cast(tf.pow(sigma, 2), tf.float32)\n",
    "        dv = tf.divide(fenzi, fenmu)\n",
    "        return tf.exp(dv)\n",
    "\n",
    "    def planB(self, height, width):\n",
    "        return tf.zeros((height, width))\n",
    "\n",
    "    def generateHeatMap(self, height, width, joints, num_joints, maxlenght):\n",
    "\n",
    "        hm = []\n",
    "        coord = []\n",
    "        for i in range(int(num_joints)):\n",
    "\n",
    "            tmp = (tf.sqrt(maxlenght) * maxlenght * 10 / 4096.) + 2\n",
    "            s = tf.cast(tmp, tf.int32)\n",
    "            x = tf.cast(joints[i * 3], tf.float64)\n",
    "            y = tf.cast(joints[i * 3 + 1], tf.float64)\n",
    "\n",
    "            ht = tf.cond(\n",
    "                (tf.equal(joints[i * 3 + 2], 1.)),\n",
    "                lambda: self._makeGaussian(height, width, s,\n",
    "                                           center=(tf.cast(x , tf.int32), tf.cast(y , tf.int32))),\n",
    "                lambda: self.planB(height, width)\n",
    "            )\n",
    "            ht = tf.expand_dims(ht, -1)\n",
    "            hm.append(ht)\n",
    "\n",
    "        return hm\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    def read_and_decode(self, filename, img_size=256,label_size=14, heatmap_size=64,  flipping=False,\n",
    "                        color_jitting=True, rotate=30, batch_size=32, isvalid=False):\n",
    "\n",
    "        feature = {'img_raw': tf.FixedLenFeature([], tf.string),\n",
    "                   'label': tf.FixedLenFeature([], tf.string),\n",
    "                   'center': tf.FixedLenFeature([], tf.string),\n",
    "                   'h': tf.FixedLenFeature([], tf.int64),\n",
    "                   'w': tf.FixedLenFeature([], tf.int64),\n",
    "                   'bh': tf.FixedLenFeature([], tf.int64),\n",
    "                   'bw': tf.FixedLenFeature([], tf.int64),\n",
    "\n",
    "                   'img_name': tf.FixedLenFeature([], tf.string),\n",
    "                   }\n",
    "        # Create a list of filenames and pass it to a queue\n",
    "        filename_queue = tf.train.string_input_producer([filename])\n",
    "        # Define a reader and read the next record\n",
    "\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "        # Decode the record read by the reader\n",
    "        features = tf.parse_single_example(serialized_example, features=feature)\n",
    "        # Convert the image data from string back to the numbers\n",
    "\n",
    "\n",
    "\n",
    "        center = tf.decode_raw(features['center'], tf.float32)\n",
    "        center = tf.reshape(center, [2, ])\n",
    "\n",
    "        label = tf.decode_raw(features['label'], tf.int32)\n",
    "        label = tf.reshape(label, [label_size, 3])\n",
    "        label=tf.cast(label,tf.float32)\n",
    "\n",
    "        height = tf.cast(features['h'], tf.int32)\n",
    "        width = tf.cast(features['w'], tf.int32)\n",
    "\n",
    "        boxh = tf.cast(features['bh'], tf.int32)\n",
    " \n",
    "        boxw = tf.cast(features['bw'], tf.int32)\n",
    "        \n",
    "        \n",
    "        img = tf.decode_raw(features['img_raw'], tf.uint8)\n",
    "\n",
    "        # Cast label data into int32\n",
    "        # label = tf.cast(features['label'],tf.float32)\n",
    "        # Reshape image data into the original shape\n",
    "\n",
    "        img_name = features['img_name']\n",
    "        res_256 = tf.constant([img_size,img_size],dtype=tf.float32)\n",
    "        res_64 = tf.constant([heatmap_size,heatmap_size],dtype=tf.float32)\n",
    "        \n",
    "        #return center,boxh,boxw\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        scale = tf.stack([boxh,boxw],axis=0)\n",
    "        scale=tf.cast(scale,tf.float32)\n",
    "        img = tf.reshape(img, [height, width, 3])\n",
    "\n",
    "        crop_img = crop(img,height, width,center, scale, res_256,)\n",
    "        crop_img.set_shape([img_size,img_size,3])\n",
    "\n",
    "        coord = transformPreds(coords=label[:, 0:2], center=center,\n",
    "                                    scale=scale, res=res_64)\n",
    "        coord = tf.squeeze(coord)\n",
    "        label_exp =tf.expand_dims( label[:,-1], -1)\n",
    "        coord = tf.squeeze(tf.reshape(tf.concat([coord,label_exp],axis=1),[-1,1]))\n",
    "        heatmap = self.generateHeatMap(heatmap_size, heatmap_size, coord, label_size , heatmap_size * 1.)\n",
    "        repeat = []\n",
    "        for i in range(len(heatmap)):\n",
    "            heatmap[i] = tf.squeeze(heatmap[i])\n",
    "        heatmap = tf.stack(heatmap,axis=-1)\n",
    "        for i in range(self.nstack):\n",
    "            repeat.append(heatmap)\n",
    "        heatmap = tf.stack(repeat, axis=0)\n",
    "        \n",
    "        if batch_size:\n",
    "    \n",
    "                min_after_dequeue = 10\n",
    "                capacity = min_after_dequeue + 4 * batch_size\n",
    "                return tf.train.shuffle_batch([crop_img, heatmap, center,scale, img_name,label,coord],\n",
    "                                                               batch_size=batch_size,\n",
    "                                                               num_threads=4,\n",
    "                                                               capacity=capacity,\n",
    "                                                               min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "        else:\n",
    "            return img, label\n",
    "    \n",
    "\n",
    "    def start(self):\n",
    "        crop_img, heatmap, center,scale, img_name,gt,crd = self.getData()\n",
    "        \n",
    "        rever = reverseFromHt(heatmap, nstack=self.nstack, batch_size=self.batch_size, num_joint=14, scale=scale, center=center, res=[64, 64])\n",
    "        \n",
    "        scale = tf.cast(tf.squeeze(tf.transpose(scale)), tf.float32)\n",
    "        center = tf.cast(tf.squeeze(tf.transpose(center)), tf.float32)\n",
    "        label = tf.reshape(crd,[self.batch_size, 14,3])\n",
    "        ori_rever =  transformPreds(label[:, 0:2], center, scale, tf.constant([64., 64.]), reverse=1)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        init = tf.group(tf.global_variables_initializer(),\n",
    "                        tf.local_variables_initializer())\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=self.sess)\n",
    "\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        for i in range(1):\n",
    "            rev,gts= self.sess.run([rever, ori_rever]) \n",
    "            print(rev,gts)\n",
    "#         print(a1,b1,c1,d1,e1,f1)\n",
    "        \n",
    "        coord.request_stop()\n",
    "        #\n",
    "        #     # Wait for threads to finish.\n",
    "        coord.join(threads)\n",
    "        self.sess.close()\n",
    "        return rev,gts\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max num is 10000\n",
      "/media/bnrc2/_backup/dataset/new_tfrecord/test.tfrecords\n",
      "record file exist!!\n",
      "(14, 2)\n",
      "(14, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot reshape a tensor with 84 elements to shape [14,3] (42 elements) for 'Reshape_32' (op: 'Reshape') with input shapes: [2,42], [2] and with input tensors computed as partial shapes: input[1] = [14,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot reshape a tensor with 84 elements to shape [14,3] (42 elements) for 'Reshape_32' (op: 'Reshape') with input shapes: [2,42], [2] and with input tensors computed as partial shapes: input[1] = [14,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-892ebe0d01f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     tf.local_variables_initializer())\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-74688fd42ec2>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mori_rever\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtransformPreds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   3936\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3937\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 3938\u001b[0;31m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   3939\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3940\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf14/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot reshape a tensor with 84 elements to shape [14,3] (42 elements) for 'Reshape_32' (op: 'Reshape') with input shapes: [2,42], [2] and with input tensors computed as partial shapes: input[1] = [14,3]."
     ]
    }
   ],
   "source": [
    "test = DataGenerator(imgdir=\"/media/bnrc2/_backup/ai/ai_challenger_keypoint_train_20170902/keypoint_train_images_20170902/\", nstack= 2,label_dir=\"/media/bnrc2/_backup/ai/ai_challenger_keypoint_train_20170902/keypoint_train_annotations_20170909.json\",\n",
    "                               out_record=\"/media/bnrc2/_backup/dataset/new_tfrecord/test.tfrecords\",num_txt=\"/media/bnrc2/_backup/dataset/new_tfrecord/test.txt\",\n",
    "                               batch_size=2, name=\"train_mini\", is_aug=False,isvalid=False, refine_num = 10000)\n",
    "\n",
    "init = tf.group(tf.global_variables_initializer(),\n",
    "                    tf.local_variables_initializer())\n",
    "\n",
    "a ,b= test.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.reshape(a,[14,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(b.reshape([14,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a = np.squeeze(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = a[0,:].astype(np.uint8)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = b[0,0,:]\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = np.zeros([14,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for joint in range(label.shape[-1]):\n",
    "    single_data = label\n",
    "    idx = np.unravel_index(single_data[:, :, joint].argmax(), (64, 64))\n",
    "   \n",
    "\n",
    "    res[joint][0] = idx[1]\n",
    "    res[joint][1] = idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = (res * 4).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(14):\n",
    "    cv2.circle(im, (int(res[i][0]) , int(res[i][1])) , 5, (0, 255, 155), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(a)\n",
    "a1 = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = b.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(b.shape[0]):\n",
    "    cv2.circle(a1, (int(b[i][0]) , int(b[i][1])) , 1, (0, 255, 155), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center = (422,382.5)\n",
    "scale = (569,179)\n",
    "\n",
    "x1 = center[0] - scale[1] /2\n",
    "x2 = center[0] + scale[1] / 2\n",
    "y1 = center[1] - scale[0] / 2\n",
    "y2 = center[1] + scale[0] / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.line(a,(int(x1),int(y1)), (int(x1), int(y2)),(0,255,255),10)\n",
    "cv2.line(a,(int(x1),int(y1)), (int(x2), int(y1)),(0,255,255),10)\n",
    "cv2.line(a,(int(x2),int(y2)), (int(x1), int(y2)),(0,255,255),10)\n",
    "cv2.line(a,(int(x2),int(y2)), (int(x2), int(y1)),(0,255,255),10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(ori.shape[0]):\n",
    "    cv2.circle(im, (int(ori[i][0]), int(ori[i][1])), 10, (0, 255, 155), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gg = [65,65]\n",
    "print(gg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = tf.reshape(a,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = tf.cast(tf.argmax(b,0),tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = tf.cast(tf.div(c,tf.constant([64],dtype=tf.int32)),tf.int32)\n",
    "e = tf.subtract(c, tf.multiply(d,tf.constant([64],dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run([d,e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a.reshape([-11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_predictions = dict()\n",
    "valid_predictions['image_ids'] = []\n",
    "valid_predictions['annos'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"sasa\"\n",
    "if name in valid_predictions['image_ids']:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf14]",
   "language": "python",
   "name": "conda-env-tf14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
